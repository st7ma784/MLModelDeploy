#!/bin/bash
#
# Auto-generated by test-tube (https://github.com/williamFalcon/test-tube)
#################

# set a job name
#SBATCH --job-name=second_wandb_trial_batchv0
#################
# a file for job output, you can check job progress
#SBATCH --output=    #EXAMPLE: /nobackup/projects/<PROJECT>/<USER>.../your/path/.../logs/second_wandb_trial_batch/slurm_out_logs/trial_0_2022-08-26__17-39-16_slurm_output_%j.out
#################
# a file for errors
#SBATCH --error=/nobackup/projects/<PROJECT>/<USER>.../your/path/.../logs/second_wandb_trial_batch/slurm_err_logs/trial_0_2022-08-26__17-39-16_slurm_output_%j.err
#################
# time needed for job
#SBATCH --time=24:00:00
#################

# gpus per node
#SBATCH --gres=gpu:4   # also requests portion of CPU and Memory
#################

# number of requested nodes
#SBATCH --nodes=2
#################
# slurm will send a signal this far out before it kills the job -- triggers auto save with PL
#SBATCH --signal=USR1@60 
#
#IF you dont want this behaviour, add this into the script
#from pytorch_lightning.plugins.environments import SLURMEnvironment
#trainer = Trainer(plugins=[SLURMEnvironment(auto_requeue=False)])
# 
#
#
#################
# Have SLURM send you an email when the job ends or fails
#SBATCH --mail-type=END,FAIL
#SBATCH --mail-user=st7ma784@gmail.com
# Project account for Bede
#SBATCH --account=bdlan05
#################
# request gpu partition on Bede
#SBATCH --partition=gpu
#################
source activate open-ce
srun python3 /nobackup/projects/<Project>/$USER/<repo>/trainagent.py
